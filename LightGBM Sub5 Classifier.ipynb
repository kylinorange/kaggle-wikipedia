{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import sys, os, gc, types\n",
    "import time\n",
    "from subprocess import check_output\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_paths = [\n",
    "    \"/data/kaggle-wikipedia/data/\",\n",
    "    \"/Users/jiayou/Dropbox/JuanCode/Kaggle/Wikipedia/data/\",\n",
    "    \"/Users/jiayou/Dropbox/Documents/JuanCode/Kaggle/Wikipedia/data/\"\n",
    "]\n",
    "root = None\n",
    "for p in root_paths:\n",
    "    if os.path.exists(p):\n",
    "        root = p\n",
    "        break\n",
    "print(check_output([\"ls\", root]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "median_data = []\n",
    "median_name = ['49_fix', 'weekday_fix', 'weekend_fix', 'dow0', 'dow1', 'dow2', 'dow3', 'dow4', 'dow5', 'dow6']\n",
    "for name in median_name:\n",
    "    median_data.append(pd.read_pickle(root + 'median_{}.pkl'.format(name)))\n",
    "\n",
    "date_df = pd.read_csv(root + 'date_df.csv')\n",
    "page_df = pd.read_pickle(root + 'page_ohe.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(root + 'train_1.csv')\n",
    "# train.fillna(0, inplace = True)\n",
    "# train = train.where(train.notnull(), median_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(train.columns[1:50], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train.melt(id_vars=['Page'], var_name='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct ABT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.merge(page_df, how='left', on='Page')\n",
    "train_df = train_df.merge(date_df.drop('date_str', axis = 1), how='left', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_days = 62\n",
    "if val_days != 0:\n",
    "    for j in range(len(median_name)):\n",
    "        last_day = median_data[j].iloc[:, -val_days-1].values.reshape((len(median_data[j]),1))\n",
    "        for i in range(-val_days, 0):\n",
    "            median_data[j].iloc[:, i] = last_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "median_df = []\n",
    "\n",
    "for i in range(len(median_name)):\n",
    "    cur_median = median_data[i].melt(\n",
    "        id_vars=['Page'], \n",
    "        var_name='date', \n",
    "        value_name='median_{}'.format(median_name[i])\n",
    "    )\n",
    "    if i != 0:\n",
    "        cur_median.drop(['Page', 'date'], axis=1, inplace=True)\n",
    "    median_df.append(cur_median)\n",
    "    \n",
    "\n",
    "train_df = train_df.merge(\n",
    "    pd.concat(median_df, axis=1), \n",
    "    how='left', \n",
    "    on=['Page','date']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['isval'] = (train_df.dayofyear > 366 - val_days) & (train_df.year == 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c, dtype in zip(train_df.columns, train_df.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        train_df[c] = train_df[c].astype(np.float32)\n",
    "    if dtype == np.int64:\n",
    "        train_df[c] = train_df[c].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# del median_df, page_df, date_df, train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data and hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = 'sub5-r1'\n",
    "num_searches = 1\n",
    "boosting_rounds = 10000\n",
    "stopping_rounds = 10\n",
    "down_sample = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if down_sample is not None:\n",
    "    train_df = train_df[train_df.index % down_sample == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for mname in median_name:\n",
    "    train_df['median_{}'.format(mname)] = np.log1p(train_df['median_{}'.format(mname)])\n",
    "for mname in median_name:\n",
    "    if mname != '49_fix':\n",
    "        train_df['median_diff_{}'.format(mname)] = train_df['median_{}'.format(mname)] - train_df['median_49_fix']\n",
    "        \n",
    "train_df = train_df[train_df.value <= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_leaves': 512,\n",
    "#     'min_sum_hessian_in_leaf': 20,\n",
    "    'max_depth': 12,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.85,\n",
    "    'bagging_freq': 3,\n",
    "    'verbose': 1,\n",
    "    'num_class': 6\n",
    "#     'device' : 'gpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.sort_index(axis=1, inplace=True)\n",
    "\n",
    "train = train_df[train_df.isval == False]\n",
    "val = train_df[train_df.isval == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_list = ['value', 'isval', 'Page', 'date']\n",
    "\n",
    "lgb_train = lgb.Dataset(\n",
    "    train.drop(drop_list, axis = 1), \n",
    "    train.value,\n",
    ")\n",
    "lgb_eval = lgb.Dataset(\n",
    "    val.drop(drop_list, axis = 1), \n",
    "    val.value, \n",
    "    reference=lgb_train,\n",
    ")\n",
    "\n",
    "# del train, val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n",
    "# binary error\n",
    "def SMAPE(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    y_true = np.round(np.expm1(labels))\n",
    "    y_pred = np.round(np.expm1(preds))\n",
    "    loss = np.mean(np.abs(y_true - y_pred) / np.maximum(1e-6, (np.abs(y_true) + np.abs(y_pred)))) * 200\n",
    "    return 'SMAPE', loss, False\n",
    "\n",
    "def SMAPE_2(preds, true):\n",
    "    y_true = np.round(np.expm1(true))\n",
    "    y_pred = np.round(np.expm1(preds))\n",
    "    loss = np.mean(np.abs(y_true - y_pred) / np.maximum(1e-6, (np.abs(y_true) + np.abs(y_pred)))) * 200\n",
    "    return loss\n",
    "\n",
    "def SMAPE_3(pred, true):\n",
    "    y_true = true\n",
    "    y_pred = pred\n",
    "    loss = np.mean(np.abs(y_true - y_pred) / np.maximum(1e-6, (np.abs(y_true) + np.abs(y_pred)))) * 200\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(num_searches):\n",
    "    print('Start LightGBM training...')\n",
    "    # train\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=boosting_rounds,\n",
    "#                     feval=SMAPE,\n",
    "                    valid_sets=[lgb_train, lgb_eval],\n",
    "#                   categorical_feature=[],\n",
    "                    early_stopping_rounds=stopping_rounds)\n",
    "\n",
    "    print('Save model...')\n",
    "    # save model to file\n",
    "    gbm.save_model('model.{}.txt'.format(name))\n",
    "\n",
    "    print('Plot feature importances...') \n",
    "    ax = lgb.plot_importance(gbm, max_num_features=100, importance_type='gain', title = 'gain')\n",
    "    plt.show()\n",
    "    ax = lgb.plot_importance(gbm, max_num_features=100, importance_type='split', title = 'split')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_abt = val.drop(['value', 'isval', 'Page', 'date'], axis=1)\n",
    "val_pred = gbm.predict(val_abt, num_iteration=gbm.best_iteration)\n",
    "val_visit = np.argmax(val_pred, axis=1)\n",
    "print('val SMAPE: ', SMAPE_3(val_visit, val.value.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/36780\n",
    "- https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/38274#215155"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(root + 'key_1_modified.csv')\n",
    "\n",
    "test_date_df = pd.read_csv(root + 'test_date_df.csv')\n",
    "page_df = pd.read_pickle(root + 'page_ohe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "median_data = []\n",
    "median_name = ['49_fix', 'weekday_fix', 'weekend_fix', 'dow0', 'dow1', 'dow2', 'dow3', 'dow4', 'dow5', 'dow6']\n",
    "for mname in median_name:\n",
    "    median_data.append(pd.read_pickle(root + 'median_{}.pkl'.format(mname)))\n",
    "    \n",
    "for i in range(len(median_data)):\n",
    "    page_df['median_{}'.format(median_name[i])] = np.log1p(median_data[i].iloc[:, -1])\n",
    "for i in range(len(median_data)):\n",
    "    if i != 0:\n",
    "        page_df['median_diff_{}'.format(median_name[i])] = page_df['median_{}'.format(median_name[i])] - page_df['median_49_fix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.merge(page_df, how='left', on='Page')\n",
    "test = test.merge(test_date_df, how='left', on='date')\n",
    "\n",
    "for c, dtype in zip(test.columns, test.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        test[c] = test[c].astype(np.float32)\n",
    "    if dtype == np.int64:\n",
    "        test[c] = test[c].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.sort_index(axis=1, inplace=True)\n",
    "\n",
    "test_df = test.drop(['Page', 'date', 'Id'], axis=1)\n",
    "pred = gbm.predict(test_df, num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visit = np.argmax(pred, axis=1)\n",
    "pred_df = pd.DataFrame({'Id':test.Id,'Visits':visit})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df.to_csv(\n",
    "    os.path.join(root, 'sub5_prediction.{}.csv'.format(name)), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
